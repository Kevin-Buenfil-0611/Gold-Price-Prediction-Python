{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:08<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 4562, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 1044.722052\n",
      "                               Adjusted R-Squared  R-Squared    RMSE  \\\n",
      "Model                                                                  \n",
      "HuberRegressor                               1.00       1.00    4.66   \n",
      "LassoLarsCV                                  1.00       1.00    4.69   \n",
      "Lars                                         1.00       1.00    4.69   \n",
      "OrthogonalMatchingPursuitCV                  1.00       1.00    4.69   \n",
      "LassoLarsIC                                  1.00       1.00    4.69   \n",
      "LarsCV                                       1.00       1.00    4.69   \n",
      "TransformedTargetRegressor                   1.00       1.00    4.69   \n",
      "RANSACRegressor                              1.00       1.00    4.69   \n",
      "LinearRegression                             1.00       1.00    4.69   \n",
      "BayesianRidge                                1.00       1.00    4.69   \n",
      "RidgeCV                                      1.00       1.00    4.82   \n",
      "ExtraTreesRegressor                          1.00       1.00    6.07   \n",
      "Ridge                                        1.00       1.00    6.07   \n",
      "LassoLars                                    1.00       1.00    6.10   \n",
      "PassiveAggressiveRegressor                   1.00       1.00    6.33   \n",
      "RandomForestRegressor                        1.00       1.00    6.34   \n",
      "LGBMRegressor                                1.00       1.00    6.40   \n",
      "BaggingRegressor                             1.00       1.00    6.52   \n",
      "XGBRegressor                                 1.00       1.00    6.64   \n",
      "HistGradientBoostingRegressor                1.00       1.00    6.74   \n",
      "SGDRegressor                                 1.00       1.00    7.48   \n",
      "LinearSVR                                    1.00       1.00    7.62   \n",
      "OrthogonalMatchingPursuit                    1.00       1.00    7.70   \n",
      "GradientBoostingRegressor                    1.00       1.00    7.92   \n",
      "DecisionTreeRegressor                        1.00       1.00    8.34   \n",
      "ExtraTreeRegressor                           1.00       1.00    8.41   \n",
      "LassoCV                                      1.00       1.00    9.57   \n",
      "Lasso                                        1.00       1.00    9.60   \n",
      "KNeighborsRegressor                          1.00       1.00   13.78   \n",
      "AdaBoostRegressor                            1.00       1.00   30.78   \n",
      "ElasticNet                                   0.98       0.98   78.10   \n",
      "ElasticNetCV                                 0.98       0.98   79.91   \n",
      "SVR                                          0.97       0.97   89.45   \n",
      "NuSVR                                        0.97       0.97   93.18   \n",
      "MLPRegressor                                 0.95       0.95  120.41   \n",
      "PoissonRegressor                             0.94       0.94  124.59   \n",
      "TweedieRegressor                             0.94       0.94  128.50   \n",
      "GammaRegressor                               0.93       0.93  140.44   \n",
      "DummyRegressor                              -0.01      -0.00  530.78   \n",
      "QuantileRegressor                           -0.11      -0.10  557.05   \n",
      "KernelRidge                                 -2.90      -2.88 1044.91   \n",
      "GaussianProcessRegressor                    -6.60      -6.57 1459.54   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "HuberRegressor                       0.04  \n",
      "LassoLarsCV                          0.01  \n",
      "Lars                                 0.01  \n",
      "OrthogonalMatchingPursuitCV          0.01  \n",
      "LassoLarsIC                          0.01  \n",
      "LarsCV                               0.01  \n",
      "TransformedTargetRegressor           0.00  \n",
      "RANSACRegressor                      0.01  \n",
      "LinearRegression                     0.01  \n",
      "BayesianRidge                        0.01  \n",
      "RidgeCV                              0.00  \n",
      "ExtraTreesRegressor                  0.55  \n",
      "Ridge                                0.01  \n",
      "LassoLars                            0.01  \n",
      "PassiveAggressiveRegressor           0.01  \n",
      "RandomForestRegressor                1.32  \n",
      "LGBMRegressor                        0.04  \n",
      "BaggingRegressor                     0.13  \n",
      "XGBRegressor                         0.07  \n",
      "HistGradientBoostingRegressor        0.14  \n",
      "SGDRegressor                         0.03  \n",
      "LinearSVR                            0.01  \n",
      "OrthogonalMatchingPursuit            0.01  \n",
      "GradientBoostingRegressor            0.57  \n",
      "DecisionTreeRegressor                0.02  \n",
      "ExtraTreeRegressor                   0.01  \n",
      "LassoCV                              0.07  \n",
      "Lasso                                0.01  \n",
      "KNeighborsRegressor                  0.01  \n",
      "AdaBoostRegressor                    0.28  \n",
      "ElasticNet                           0.01  \n",
      "ElasticNetCV                         0.05  \n",
      "SVR                                  0.76  \n",
      "NuSVR                                0.52  \n",
      "MLPRegressor                         1.84  \n",
      "PoissonRegressor                     0.02  \n",
      "TweedieRegressor                     0.01  \n",
      "GammaRegressor                       0.01  \n",
      "DummyRegressor                       0.00  \n",
      "QuantileRegressor                    0.41  \n",
      "KernelRidge                          0.49  \n",
      "GaussianProcessRegressor             1.32  \n",
      "Mejor modelo: HuberRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/23 17:45:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.75748639120675, MAE: 2.9515764445855925\n",
      "Modelo guardado en huber_regressor_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Training Pipeline Notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# 1. Cargar los datos procesados\n",
    "with open(\"processed_data.pkl\", \"rb\") as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)\n",
    "\n",
    "# 2. LazyPredict para probar varios modelos\n",
    "reg = LazyRegressor()\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)\n",
    "\n",
    "# 3. Seleccionar el mejor modelo según el MSE o MAE\n",
    "best_model_name = models.index[0]  # Tomando el modelo con mejor rendimiento\n",
    "print(f\"Mejor modelo: {best_model_name}\")\n",
    "\n",
    "# 4. Registrar el mejor modelo en MLFlow\n",
    "mlflow.set_experiment(\"Gold Price Regression\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Crear y entrenar el modelo HuberRegressor\n",
    "    model = HuberRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Registro del modelo en MLflow\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # Realizar predicciones y calcular métricas\n",
    "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "    \n",
    "    # Registrar las métricas en MLflow\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    \n",
    "    # Imprimir las métricas\n",
    "    print(f\"MSE: {mse}, MAE: {mae}\")\n",
    "\n",
    "     # Guardar el modelo entrenado en un archivo local usando joblib\n",
    "    model_path = \"huber_regressor_model.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Modelo guardado en {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
